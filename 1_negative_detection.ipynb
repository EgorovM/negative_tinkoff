{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm as tq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_texts = pd.read_csv('pulse_stage1_patch.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    33466\n",
       "True      1141\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_texts.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_texts.query('label')[['message']].to_csv('toxic.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_texts.query('label != True')[['message']].to_csv('non_toxic.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_texts.query('label')[['message']].to_excel('toxic.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_texts.query('label != True')[['message']].to_excel('non_toxic.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мичил\n",
    "- Заменить ё на е\n",
    "- Исправить грамматику\n",
    "- Многоточия, вопросительные знаки, восклицательные\n",
    "- Сократить многогласия (фууу -> фу, ахахахахах -> аха)\n",
    "- Токсичная улыбка скобка\n",
    "- Разделить соединенные слова\n",
    "\n",
    "Снежана\n",
    "- Муты->слова (точки, звездочки)\n",
    "- Токсичные окончания слов (пиздаболище...)\n",
    "- Сокращения в слова\n",
    "- Исправление опечатков мата по возможности \n",
    "- Омонимы в контексте (имеют->ебут)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_texts = pd.read_csv('data_with_clean.csv', sep='\\t', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def split_text(text):\n",
    "    return re.split(r'\\.|,|-| |\\n|;|\\?|!|\\)|\\(|«|\\\"|/', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = split_text(\" \".join(df_texts['message'].to_list()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Повторения букв"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "letters = 'аеиоуыэюяё'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "double_char_words = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for letter in letters:\n",
    "    double_char_words.extend(list(filter(lambda x: letter * 3 in x, words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_long_letters(text):\n",
    "    for letter in letters:\n",
    "        for i in reversed(range(3, 7)):   \n",
    "            text = text.replace(letter * i, letter)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "repeat_chars_dict = dict([(ch, replace_long_letters(ch)) for ch in double_char_words])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Смешнявки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "funny_comment = list(filter(lambda word: ('хах' in word and 'аха' in word), words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "funny_dict = dict.fromkeys(funny_comment, 'ахах')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Муты и сокращения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('mutes_stars.txt', 'w') as f:\n",
    "    f.write(\"\\n\".join(list(filter(lambda word: '*' in word, words))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('mutes_dots.txt', 'w') as f:\n",
    "    f.write(\"\\n\".join(list(filter(lambda word: '..' in word and not word.endswith('...'), words))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Дал снеге расшифровать"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Звездочки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "stars = open('mutes_stars_filled.txt', encoding='cp1251').read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "stars_dict = {a.split(';')[0]: a.split(';')[1].strip() for a in stars}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Точки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dots = open('mutes_dots_filled.txt', encoding='cp1251').read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dots_dict = {a.split(';')[0]: a.split(';')[1].strip() for a in dots}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сокращения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "sokr = open('abbreviatury.txt').read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "sokr_dict = {a.split(';')[0]: a.split(';')[1].strip() for a in sokr}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = df_texts['message'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(messages)):\n",
    "    message = messages[i]\n",
    "    message = \" \".join([dots_dict.get(word, word) for word in message.lower().split()])\n",
    "    message = \" \".join([sokr_dict.get(word, word) for word in message.lower().split()])\n",
    "    \n",
    "    messages[i] = message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обработка текста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import pymorphy2\n",
    "import hunspell\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = sorted(set(stopwords.words('russian') + open('stop_words.txt').read().splitlines()))\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "h_ru = hunspell.Hunspell('ru_RU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import symspellpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import opencorpora\n",
    "\n",
    "corpus = opencorpora.CorpusReader('annot.opcorpora.xml')\n",
    "catalog = corpus.catalog()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4007/4007 [01:12<00:00, 55.13it/s] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def recursive_flatten_generator(array):\n",
    "    lst = []\n",
    "    for i in array:\n",
    "        if isinstance(i, list):\n",
    "            lst.extend(recursive_flatten_generator(i))\n",
    "        else:\n",
    "            lst.append(i)\n",
    "    return lst\n",
    "\n",
    "def read_list(filepath, codec):\n",
    "    with codecs.open(filepath, 'r',codec) as file:\n",
    "        data = file.readlines()\n",
    "        data = [line.rstrip() for line in data]\n",
    "    return data\n",
    "\n",
    "\n",
    "from  more_itertools import unique_everseen\n",
    "\n",
    "corp_index = [item[0] for item in catalog]\n",
    "\n",
    "texts = []\n",
    "for ind in tq(corp_index):\n",
    "    corp = corpus.words(ind)\n",
    "    texts.append(corp)\n",
    "\n",
    "texts = list(unique_everseen(texts))\n",
    "\n",
    "texts = recursive_flatten_generator(texts)\n",
    "\n",
    "sym_spell = symspellpy.SymSpell(max_dictionary_edit_distance=2, prefix_length=7)\n",
    "sym_spell.create_dictionary(texts, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34480/34480 [00:00<00:00, 101722.01it/s]\n",
      "100%|██████████| 34480/34480 [00:00<00:00, 198912.05it/s]\n",
      "100%|██████████| 34480/34480 [00:00<00:00, 109222.46it/s]\n",
      "100%|██████████| 34480/34480 [00:00<00:00, 195562.71it/s]\n"
     ]
    }
   ],
   "source": [
    "#'Diva004' -> 'Diva 004'- divides letters and digits\n",
    "R = r'(?i)(?:(?<=\\d)(?=[а-яa-zё])|(?<=[а-яa-zё])(?=\\d))'\n",
    "sep_tags = [re.sub(R, ' ', item) for item in tq(messages)]\n",
    "\n",
    "#'какZUMBA' -> 'как ZUMBA' - divides cases\n",
    "R_1 = r'(?:(?<=[a-zа-яё])(?=[А-ЯA-ZЁ]))'\n",
    "sep_tags = [re.sub(R_1, ' ', item) for item in tq(sep_tags)]\n",
    "\n",
    "#'душноvsдует' -> 'душно vs дует' - divides languages (en, ru)\n",
    "R_2 = r'(?i)(?:(?<=[a-z])(?=[а-яё])|(?<=[а-яё])(?=[a-z]))'\n",
    "sep_tags = [re.sub(R_2, ' ', item) for item in tq(sep_tags)]\n",
    "\n",
    "#'ДушноДует' -> 'Душно Дует' - divides camel case\n",
    "R_3 = r'(?:(?<=[a-zа-яё])(?=[A-ZА-ЯЁ]))'\n",
    "splitted_message = [re.sub(R_3, ' ', item) for item in tq(sep_tags)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(comment):\n",
    "    \"\"\"\n",
    "    Заменить ё на е + \n",
    "    Заменить смешнявки +\n",
    "    Исправить грамматику +\n",
    "    Многоточия, вопросительные знаки, восклицательные +\n",
    "    Сократить многогласия (фууу -> фу, ахахахахах -> аха) + \n",
    "    Разделить слова +\n",
    "    \"\"\"\n",
    "    \n",
    "    comment = comment.replace('ё', 'е')\n",
    "    comment = comment.lower()\n",
    "    \n",
    "    # удаление ссылок\n",
    "    comment = re.sub(r\"@[а-яА-ЯA-Za-z0-9]+\", ' ', comment)\n",
    "    comment = re.sub(r\"https?://[A-Za-z0-9./]+\", ' ', comment)\n",
    "    comment = re.sub(r\"http?://[A-Za-z0-9./]+\", ' ', comment)\n",
    "    \n",
    "    # заменить смешнявки\n",
    "    comment = \" \".join([funny_dict.get(word, word) for word in split_text(comment)])\n",
    "    \n",
    "    # Сократить многогласия\n",
    "    comment = \" \".join([repeat_chars_dict.get(word, word) for word in split_text(comment)])\n",
    "    \n",
    "    # заменить муты звездочки\n",
    "    comment = \" \".join([stars_dict.get(word, word) for word in split_text(comment)])\n",
    "    \n",
    "    # оставить только буквы\n",
    "    comment = re.sub(r\"[^а-яА-Яa-zA-Z]\", ' ', comment)\n",
    "    \n",
    "    # удалить пустоты\n",
    "    comment = re.sub(r\" +\", ' ', comment)\n",
    "    \n",
    "    # исправляем опечатки\n",
    "    new_comment = \"\"\n",
    "    \n",
    "    for word in split_text(comment):\n",
    "        if not word:\n",
    "            continue\n",
    "            \n",
    "        sym_checker = sym_spell.word_segmentation(word)\n",
    "        \n",
    "        if len(word) > 10 or sym_checker.log_prob_sum > -13:\n",
    "            new_comment += sym_checker.corrected_string\n",
    "        else:\n",
    "            new_comment += word\n",
    "            \n",
    "        new_comment += ' '\n",
    "    \n",
    "    comment = new_comment\n",
    "    \n",
    "    # в нормальную форму\n",
    "    normal_form = \" \".join([morph.parse(word)[0].normal_form for word in comment.split() if not word in stop_words])\n",
    "    \n",
    "    return normal_form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "comment = \" \".join(df_texts['message'].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "comment = clean_text(comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = split_text(comment)\n",
    "\n",
    "words.sort(key=lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_words = sorted(set(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google_trans_new import google_translator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "translator = google_translator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(lst):\n",
    "    start_time = time.time()\n",
    "    translations =[]\n",
    "    print(\"initiation\")\n",
    "    for line in lst:\n",
    "        trans = translator.translate(line, lang_tgt='ru')\n",
    "        translations.append((line, trans))\n",
    "    time.sleep(1)\n",
    "    print('time:', time.time() - start_time)\n",
    "    return translations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = process(['quit', 'exit'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 58.7 s, sys: 391 ms, total: 59.1 s\n",
      "Wall time: 59.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_texts['clean_message'] = list(map(clean_text, splitted_message))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>label</th>\n",
       "      <th>split</th>\n",
       "      <th>clean_message</th>\n",
       "      <th>question_count</th>\n",
       "      <th>voskl_count</th>\n",
       "      <th>mnogodots_count</th>\n",
       "      <th>toxic_brakets_count</th>\n",
       "      <th>digit_count</th>\n",
       "      <th>has_bad_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Пиздабол ещё тот</td>\n",
       "      <td>True</td>\n",
       "      <td>train</td>\n",
       "      <td>пиздабол</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Заколебали кукарекать, скоро весь пульс будет ...</td>\n",
       "      <td>True</td>\n",
       "      <td>train</td>\n",
       "      <td>заколебать кукарекать скоро пульс вафлера забить</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>На деле собака сутулая</td>\n",
       "      <td>True</td>\n",
       "      <td>train</td>\n",
       "      <td>дело собака сутулый</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Пшнх от сюда тварь</td>\n",
       "      <td>True</td>\n",
       "      <td>train</td>\n",
       "      <td>пойти нахуй сюда тварь</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>плати за мое молчание клоп , сутки молчу 200 б...</td>\n",
       "      <td>True</td>\n",
       "      <td>train</td>\n",
       "      <td>платить мой молчание клоп сутки молчать бакс</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             message  label  split  \\\n",
       "0                                   Пиздабол ещё тот   True  train   \n",
       "1  Заколебали кукарекать, скоро весь пульс будет ...   True  train   \n",
       "2                             На деле собака сутулая   True  train   \n",
       "3                                 Пшнх от сюда тварь   True  train   \n",
       "4  плати за мое молчание клоп , сутки молчу 200 б...   True  train   \n",
       "\n",
       "                                      clean_message  question_count  \\\n",
       "0                                          пиздабол               0   \n",
       "1  заколебать кукарекать скоро пульс вафлера забить               0   \n",
       "2                               дело собака сутулый               0   \n",
       "3                            пойти нахуй сюда тварь               0   \n",
       "4      платить мой молчание клоп сутки молчать бакс               0   \n",
       "\n",
       "   voskl_count  mnogodots_count  toxic_brakets_count  digit_count  \\\n",
       "0            0                0                    0            0   \n",
       "1            0                0                    0            0   \n",
       "2            0                0                    0            0   \n",
       "3            0                0                    0            0   \n",
       "4            0                0                    0            3   \n",
       "\n",
       "   has_bad_word  \n",
       "0          True  \n",
       "1          True  \n",
       "2         False  \n",
       "3          True  \n",
       "4         False  "
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_texts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_words_dict = ['бля', 'сук', 'нах', 'заеб', 'хуй', 'пидор', 'твар', 'пизд', 'шлюх', 'трах', 'мудак', 'ебат']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_texts['question_count'] = df_texts['message'].apply(lambda x: x.count('?'))\n",
    "df_texts['voskl_count'] = df_texts['message'].apply(lambda x: x.count('!'))\n",
    "df_texts['mnogodots_count'] = df_texts['message'].apply(lambda x: x.count('...'))\n",
    "df_texts['toxic_brakets_count'] = df_texts['message'].apply(lambda x: x.count(')'))\n",
    "df_texts['digit_count'] = df_texts['message'].apply(lambda x: sum([a.isdigit() for a in x]))\n",
    "df_texts['has_bad_word'] = df_texts['clean_message'].apply(lambda x: any([word in x for word in bad_words_dict]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_columns = ['question_count', 'voskl_count', 'mnogodots_count', 'toxic_brakets_count', 'digit_count', 'has_bad_word']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_texts.to_csv('data_with_clean.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_texts.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "df_stripped = df_texts.query('label').append(df_texts.query('not label').sample(1130))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(max_features=3000)\n",
    "vectors = vectorizer.fit_transform(df_stripped['clean_message']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.hstack((vectors, StandardScaler().fit_transform(df_stripped[real_columns])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, df_stripped['label'], test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(random_state=42)"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RandomForestClassifier(random_state=42)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8563049853372434"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8619718309859155"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(model.predict(X_test), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features_list = range(5000, 6000, 100)\n",
    "scores = []\n",
    "\n",
    "for max_features in tq(max_features_list):\n",
    "    vectorizer = TfidfVectorizer(max_features=max_features)\n",
    "    vectors = vectorizer.fit_transform(df_stripped['clean_message']).toarray()\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(vectors, df_stripped['label'], test_size=0.3, random_state=42)\n",
    "    model = RandomForestClassifier(random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    scores.append(f1_score(model.predict(X_test), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fd161e12fd0>]"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(max_features_list, scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "максимальное кол-во слов: 5500\n"
     ]
    }
   ],
   "source": [
    "MAX_FEATURES = max_features_list[scores.index(max(scores))]\n",
    "print('максимальное кол-во слов:', MAX_FEATURES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(max_features=MAX_FEATURES)\n",
    "vectors = vectorizer.fit_transform(df_stripped['clean_message']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.hstack((vectors, StandardScaler().fit_transform(df_stripped[real_columns])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, df_stripped['label'], test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(random_state=42)"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RandomForestClassifier(random_state=42)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_name(i):\n",
    "    return (vectorizer.get_feature_names() + real_columns)[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8577712609970675"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8628005657708628"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(model.predict(X_test), y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- max - 0.867231638418079\n",
    "- new_max - 0.8716502115655854 (without deleting words with one length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature ranking:\n",
      "1. feature digit_count (0.109178)\n",
      "2. feature has_bad_word (0.040110)\n",
      "3. feature toxic_brakets_count (0.029450)\n",
      "4. feature купить (0.017553)\n",
      "5. feature акция (0.014871)\n",
      "6. feature цена (0.014698)\n",
      "7. feature компания (0.012226)\n",
      "8. feature бумага (0.011224)\n",
      "9. feature тупой (0.010013)\n",
      "10. feature работать (0.009131)\n",
      "11. feature дебил (0.006793)\n",
      "12. feature отчёт (0.006471)\n",
      "13. feature продать (0.006105)\n",
      "14. feature хороший (0.006017)\n",
      "15. feature минус (0.005921)\n",
      "16. feature думать (0.005649)\n",
      "17. feature брать (0.005176)\n",
      "18. feature средний (0.005053)\n",
      "19. feature рост (0.005049)\n",
      "20. feature question_count (0.004893)\n",
      "21. feature ждать (0.004715)\n",
      "22. feature деньга (0.004711)\n",
      "23. feature точно (0.004612)\n",
      "24. feature взять (0.004354)\n",
      "25. feature стоить (0.004269)\n",
      "26. feature упасть (0.004245)\n",
      "27. feature падать (0.003955)\n",
      "28. feature продавать (0.003865)\n",
      "29. feature говно (0.003774)\n",
      "30. feature общий (0.003742)\n",
      "31. feature рынок (0.003739)\n",
      "32. feature расти (0.003351)\n",
      "33. feature дурачок (0.003288)\n",
      "34. feature рубль (0.003264)\n",
      "35. feature сказать (0.003252)\n",
      "36. feature заявка (0.003179)\n",
      "37. feature сильно (0.002982)\n",
      "38. feature покупать (0.002940)\n",
      "39. feature хомяк (0.002935)\n",
      "40. feature графика (0.002840)\n",
      "41. feature вообще (0.002829)\n",
      "42. feature фонд (0.002769)\n",
      "43. feature ситуация (0.002726)\n",
      "44. feature покупка (0.002658)\n",
      "45. feature новость (0.002654)\n",
      "46. feature месяц (0.002647)\n",
      "47. feature делать (0.002638)\n",
      "48. feature идиот (0.002634)\n",
      "49. feature задолбать (0.002627)\n",
      "50. feature voskl_count (0.002576)\n",
      "51. feature свой (0.002566)\n",
      "52. feature вроде (0.002526)\n",
      "53. feature лох (0.002490)\n",
      "54. feature налог (0.002435)\n",
      "55. feature вчера (0.002427)\n",
      "56. feature смотреть (0.002386)\n",
      "57. feature жбан (0.002297)\n",
      "58. feature большой (0.002296)\n",
      "59. feature выбираться (0.002295)\n",
      "60. feature комиссия (0.002282)\n",
      "61. feature итог (0.002267)\n",
      "62. feature день (0.002218)\n",
      "63. feature доллар (0.002216)\n",
      "64. feature прибыль (0.002176)\n",
      "65. feature анализ (0.002172)\n",
      "66. feature докупить (0.002102)\n",
      "67. feature хотеть (0.002027)\n",
      "68. feature закупаться (0.002020)\n",
      "69. feature продажа (0.002015)\n",
      "70. feature убыток (0.002014)\n",
      "71. feature пиздец (0.001990)\n",
      "72. feature mnogodots_count (0.001987)\n",
      "73. feature интересно (0.001970)\n",
      "74. feature начать (0.001960)\n",
      "75. feature самый (0.001949)\n",
      "76. feature выше (0.001940)\n",
      "77. feature инф (0.001934)\n",
      "78. feature сразу (0.001911)\n",
      "79. feature больший (0.001895)\n",
      "80. feature висеть (0.001892)\n",
      "81. feature бан (0.001881)\n",
      "82. feature счёт (0.001817)\n",
      "83. feature исправить (0.001813)\n",
      "84. feature какой (0.001789)\n",
      "85. feature тонкий (0.001745)\n",
      "86. feature штука (0.001729)\n",
      "87. feature говорить (0.001723)\n",
      "88. feature сделать (0.001719)\n",
      "89. feature тесло (0.001709)\n",
      "90. feature разница (0.001680)\n",
      "91. feature идея (0.001659)\n",
      "92. feature тупорылый (0.001645)\n",
      "93. feature пойти (0.001617)\n",
      "94. feature странно (0.001614)\n",
      "95. feature посмотреть (0.001592)\n",
      "96. feature раз (0.001558)\n",
      "97. feature блядь (0.001553)\n",
      "98. feature объём (0.001540)\n",
      "99. feature знать (0.001539)\n",
      "100. feature пендос (0.001496)\n",
      "101. feature понять (0.001493)\n",
      "102. feature уйти (0.001493)\n",
      "103. feature пох (0.001475)\n",
      "104. feature процент (0.001473)\n",
      "105. feature баба (0.001455)\n",
      "106. feature наоборот (0.001454)\n",
      "107. feature новый (0.001429)\n",
      "108. feature канал (0.001425)\n",
      "109. feature равно (0.001424)\n",
      "110. feature шорты (0.001418)\n",
      "111. feature дать (0.001415)\n",
      "112. feature сливать (0.001404)\n",
      "113. feature дурак (0.001336)\n",
      "114. feature момент (0.001331)\n",
      "115. feature стоимость (0.001330)\n",
      "116. feature дивиденд (0.001329)\n",
      "117. feature норма (0.001326)\n",
      "118. feature заходить (0.001323)\n",
      "119. feature возможно (0.001320)\n",
      "120. feature написать (0.001302)\n",
      "121. feature решить (0.001294)\n",
      "122. feature один (0.001294)\n",
      "123. feature плита (0.001284)\n",
      "124. feature скоро (0.001279)\n",
      "125. feature плюс (0.001266)\n",
      "126. feature слить (0.001255)\n",
      "127. feature быдло (0.001255)\n",
      "128. feature усреднять (0.001254)\n",
      "129. feature бакс (0.001252)\n",
      "130. feature получить (0.001238)\n",
      "131. feature такой (0.001236)\n",
      "132. feature риск (0.001234)\n",
      "133. feature заработать (0.001230)\n",
      "134. feature вырасти (0.001222)\n",
      "135. feature дешёвый (0.001203)\n",
      "136. feature вопрос (0.001177)\n",
      "137. feature лететь (0.001173)\n",
      "138. feature сумма (0.001170)\n",
      "139. feature нужный (0.001169)\n",
      "140. feature банк (0.001168)\n",
      "141. feature правда (0.001159)\n",
      "142. feature кобель (0.001150)\n",
      "143. feature фиксировать (0.001144)\n",
      "144. feature временно (0.001141)\n",
      "145. feature закрыть (0.001141)\n",
      "146. feature например (0.001138)\n",
      "147. feature жопа (0.001133)\n",
      "148. feature добрый (0.001131)\n",
      "149. feature тупица (0.001130)\n",
      "150. feature смысл (0.001124)\n"
     ]
    }
   ],
   "source": [
    "importances = model.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in model.estimators_],\n",
    "             axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "for f in range(150):\n",
    "    print(\"%d. feature %s (%f)\" % (f + 1, get_feature_name(indices[f]), importances[indices[f]]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs102",
   "language": "python",
   "name": "cs102"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
